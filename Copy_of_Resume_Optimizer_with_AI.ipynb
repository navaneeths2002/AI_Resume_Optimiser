{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEyKJMoq295b",
        "outputId": "ef6592cc-96e9-4726-9658-30e66d97dce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: weasyprint in /usr/local/lib/python3.11/dist-packages (65.1)\n",
            "Requirement already satisfied: pydyf>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.11.0)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.17.1)\n",
            "Requirement already satisfied: tinyhtml5>=2.0.0b1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (2.0.0)\n",
            "Requirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.4.0)\n",
            "Requirement already satisfied: cssselect2>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.8.0)\n",
            "Requirement already satisfied: Pyphen>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (0.17.2)\n",
            "Requirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (11.2.1)\n",
            "Requirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.58.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint) (2.22)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.8.0->weasyprint) (0.5.1)\n",
            "Requirement already satisfied: brotli>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (1.1.0)\n",
            "Requirement already satisfied: zopfli>=0.1.4 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (0.2.3.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install weasyprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w09BF4f-X0d9"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "import openai\n",
        "from markdown import markdown\n",
        "from weasyprint import HTML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LSWkbBFgIFx"
      },
      "source": [
        "**importing the resume as a markdown(md) file for proper understanding to the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jnk0y4e3X7mi",
        "outputId": "5da58661-ed2c-4aaf-b061-02af9c307825"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# P A Salman Shah\n",
              "\n",
              "üìû 7559967607  \n",
              "üìß salmansha8749@gmail.com  \n",
              "\n",
              "---\n",
              "\n",
              "## üéØ Objective\n",
              "\n",
              "To secure a rewarding career in a reputed company where I can render my values and contribute constructively to the organization.\n",
              "\n",
              "---\n",
              "\n",
              "## üíº Skills\n",
              "\n",
              "- Python  \n",
              "- Django  \n",
              "- Data Analysis  \n",
              "- SQL  \n",
              "- HTML, CSS, JavaScript  \n",
              "- Power BI  \n",
              "- MS Excel  \n",
              "\n",
              "---\n",
              "\n",
              "## üéì Education\n",
              "\n",
              "**Bachelor of Technology in Computer Science and Engineering**  \n",
              "_College of Engineering Pathanapuram (2020‚Äì2024)_  \n",
              "**CGPA:** 6.58  \n",
              "\n",
              "**12th Class**  \n",
              "_Sree Buddha Central School, Pattoor (2020)_  \n",
              "**Percentage:** 77%  \n",
              "\n",
              "**10th Class**  \n",
              "_Sree Buddha Central School, Pattoor (2018)_  \n",
              "**Percentage:** 90%  \n",
              "\n",
              "---\n",
              "\n",
              "## üí° Projects\n",
              "\n",
              "### Phishing Website Detection Using Machine Learning\n",
              "- Utilized powerful machine learning algorithms, including the innovative hybrid model **LSD (LR + SVC + DT)**.\n",
              "- Employed both **soft** and **hard voting mechanisms** for improved accuracy.\n",
              "\n",
              "### YouTube Transcript Summarizer\n",
              "- Developed a **Chrome Extension** backed by a REST API.\n",
              "- Automatically summarizes video transcripts using **advanced NLP techniques**.\n",
              "\n",
              "---\n",
              "\n",
              "## üßë‚Äçüíº Internship\n",
              "\n",
              "**Rever Tech IT Solutions**  \n",
              "_Web Mining Using Python_  \n",
              "18/11/2022 ‚Äì 22/11/2022  \n",
              "\n",
              "---\n",
              "\n",
              "## üèÜ Achievements & Leadership\n",
              "\n",
              "- Class Representative  \n",
              "- College Union Member  \n",
              "- Program Coordinator  \n",
              "- College Tech Fest Coordinator  \n",
              "\n",
              "---\n",
              "\n",
              "## üìö Training\n",
              "\n",
              "**Qspiders**  \n",
              "_Python Full Stack Developer_\n",
              "\n",
              "---\n",
              "\n",
              "## ‚öΩ Interests\n",
              "\n",
              "Football, Cricket, Games\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Open and read the resume Markdown file\n",
        "with open(\"/content/P A Salman Shah.md\", \"r\", encoding=\"utf-8\") as file:\n",
        "    resume_string = file.read()\n",
        "\n",
        "# display resume\n",
        "display(Markdown(resume_string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhJtWBaSX7km"
      },
      "source": [
        "**Input the job description to make desirable resume for the position**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKR4L3AzgZq7",
        "outputId": "ba2dfb4c-9e3d-418d-d954-c576ad96acf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mandatory Skills:   Experience with Celery, utilizing web scrapers and associated libraries, Data management libraries AND utilizing async calls PostgreSQL or other TSQL based database (MySQL, MS SQL). Should have implemented Object oriented technologies, multi-tier application Experience defining and build unit tests Experience with logging Familiarity with writing and consuming APIs for integrating data from disparate sources  Good to Have Skills:   Hands-on experience with Docker  Prior experience with FastAPI and Django Prior experience with Linux and ability to navigate the file system through SSH Prior experience with AWS S3 Experience with Redis    Roles & Responsibilities:  Develop and maintain scalable backend systems using Python, with asynchronous processing via Celery and web scraping solutions. Design, implement, and optimize relational database schemas using PostgreSQL or other TSQL-based databases like MySQL or MS SQL. Build, consume, and integrate RESTful APIs to enable smooth data flow between various internal and external systems. Apply object-oriented programming principles to develop reusable, modular, and well-structured code for multi-tier applications. Write and maintain unit tests to ensure high code quality, reliability, and performance throughout the development lifecycle. Implement effective logging mechanisms to monitor, debug, and analyze backend processes and services. Work with containerization tools like Docker for deployment and environment consistency (good to have). Utilize frameworks such as FastAPI or Django for rapid and secure API development (good to have). Operate in Linux environments using SSH and interact with AWS S3 and Redis for storage and caching needs (good to have). Collaborate with cross-functional teams and maintain clear technical documentation for backend services and APIs.\n"
          ]
        }
      ],
      "source": [
        "# input job description\n",
        "jd_string = input()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-Z_kyJrX7hv"
      },
      "outputs": [],
      "source": [
        "prompt_template = lambda resume_string, jd_string : f\"\"\"\n",
        "You are a professional resume optimization expert specializing in tailoring resumes to specific job descriptions. Your goal is to optimize my resume and provide actionable suggestions for improvement to align with the target role.\n",
        "\n",
        "### Guidelines:\n",
        "1. **Relevance**:\n",
        "   - Prioritize experiences, skills, and achievements **most relevant to the job description**.\n",
        "   - Remove or de-emphasize irrelevant details to ensure a **concise** and **targeted** resume.\n",
        "   - Limit work experience section to 2-3 most relevant roles\n",
        "   - Limit bullet points under each role to 2-3 most relevant impacts\n",
        "\n",
        "2. **Action-Driven Results**:\n",
        "   - Use **strong action verbs** and **quantifiable results** (e.g., percentages, revenue, efficiency improvements) to highlight impact.\n",
        "\n",
        "3. **Keyword Optimization**:\n",
        "   - Integrate **keywords** and phrases from the job description naturally to optimize for ATS (Applicant Tracking Systems).\n",
        "\n",
        "4. **Additional Suggestions** *(If Gaps Exist)*:\n",
        "   - If the resume does not fully align with the job description, suggest:\n",
        "     1. **Additional technical or soft skills** that I could add to make my profile stronger.\n",
        "     2. **Certifications or courses** I could pursue to bridge the gap.\n",
        "     3. **Project ideas or experiences** that would better align with the role.\n",
        "\n",
        "5. **Formatting**:\n",
        "   - Output the tailored resume in **clean Markdown format**.\n",
        "   - Include an **\"Additional Suggestions\"** section at the end with actionable improvement recommendations.\n",
        "\n",
        "---\n",
        "\n",
        "### Input:\n",
        "- **My resume**:\n",
        "{resume_string}\n",
        "\n",
        "- **The job description**:\n",
        "{jd_string}\n",
        "\n",
        "---\n",
        "\n",
        "### Output:\n",
        "1. **Tailored Resume**:\n",
        "   - A resume in **Markdown format** that emphasizes relevant experience, skills, and achievements.\n",
        "   - Incorporates job description **keywords** to optimize for ATS.\n",
        "   - Uses strong language and is no longer than **one page**.\n",
        "\n",
        "2. **Additional Suggestions** *(if applicable)*:\n",
        "   - List **skills** that could strengthen alignment with the role.\n",
        "   - Recommend **certifications or courses** to pursue.\n",
        "   - Suggest **specific projects or experiences** to develop.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tgu5nc4X7e3"
      },
      "outputs": [],
      "source": [
        "prompt = prompt_template(resume_string, jd_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lauDUe2AX7bw"
      },
      "source": [
        "# **Generate Resume with GPT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v1olOgiNnrPM",
        "outputId": "327e8a0d-f172-44a1-8308-753c1af07908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using preferred model: models/gemini-1.5-flash-latest\n",
            "# P A Salman Shah\n",
            "\n",
            "üìû 7559967607  \n",
            "üìß salmansha8749@gmail.com  \n",
            "\n",
            "## Summary\n",
            "\n",
            "Highly motivated and results-oriented Python backend developer with experience in data analysis, web scraping, and API development seeking a challenging role leveraging asynchronous processing (Celery) and relational database management (PostgreSQL/MySQL). Proven ability to build scalable, maintainable, and well-tested applications using object-oriented programming principles.  Eager to contribute to a dynamic team and further develop expertise in cloud technologies (AWS) and containerization (Docker).\n",
            "\n",
            "## Skills\n",
            "\n",
            "* **Programming Languages:** Python (Django, FastAPI - *familiar*), SQL, JavaScript\n",
            "* **Frameworks/Libraries:** Celery,  Data Management Libraries (specify which ones from your projects),  Web Scraping Libraries (Beautiful Soup, Scrapy - *specify if used*),  REST API development\n",
            "* **Databases:** PostgreSQL, MySQL\n",
            "* **Tools:** Docker (familiar), Git,  Power BI, MS Excel\n",
            "* **Methodologies:** Object-Oriented Programming, Agile (mention if applicable)\n",
            "* **Other:**  Unit Testing, Logging,  Asynchronous Programming,  API Integration\n",
            "\n",
            "\n",
            "## Experience\n",
            "\n",
            "**Rever Tech IT Solutions - Web Mining using Python** (18/11/2022 ‚Äì 22/11/2022)\n",
            "\n",
            "* Developed Python scripts for web scraping, extracting specific data points and transforming them for analysis.  *(Quantify results if possible - e.g., \"Processed X amount of data points per hour\")*\n",
            "* Implemented data cleaning and preprocessing techniques to improve data quality for subsequent analysis.  *(Mention specific techniques used)*\n",
            "\n",
            "\n",
            "**Project: Phishing Website Detection Using Machine Learning**\n",
            "\n",
            "* Developed a machine learning model (LSD - LR + SVC + DT) for phishing website detection, employing both soft and hard voting mechanisms for improved accuracy. *(Quantify the accuracy improvement if possible)*\n",
            "\n",
            "\n",
            "**Project: YouTube Transcript Summarizer**\n",
            "\n",
            "* Designed and implemented a Chrome Extension utilizing a REST API and advanced NLP techniques to automatically summarize YouTube video transcripts. *(Mention NLP techniques used and any quantifiable results like summarization speed or accuracy)*\n",
            "\n",
            "\n",
            "## Education\n",
            "\n",
            "**Bachelor of Technology in Computer Science and Engineering**\n",
            "_College of Engineering Pathanapuram (2020‚Äì2024)_\n",
            "CGPA: 6.58\n",
            "\n",
            "\n",
            "## Additional Suggestions\n",
            "\n",
            "To further strengthen your resume and align it with the target job description, consider the following:\n",
            "\n",
            "1. **Skill Enhancement:**\n",
            "    * Gain hands-on experience with Celery, specifically showcasing asynchronous task management and scheduling.  Create a small project demonstrating this capability.\n",
            "    * Deepen your knowledge of PostgreSQL or MySQL, particularly in schema design and optimization.  Practice with complex queries and transactions.\n",
            "    * Expand your experience with specific web scraping libraries (e.g., Beautiful Soup, Scrapy), documenting your proficiency and showcasing projects.\n",
            "    * Familiarize yourself with Docker and containerization workflows.  Create a Dockerfile for a simple application.\n",
            "\n",
            "2. **Certification/Courses:**\n",
            "    * Consider a course focusing on advanced Python programming, including asynchronous programming concepts, and database management systems.\n",
            "    * A certification in AWS services (S3, etc.) would be beneficial.\n",
            "\n",
            "\n",
            "3. **Project Ideas:**\n",
            "    * Develop a project that combines web scraping, Celery for asynchronous processing, and a PostgreSQL database.  This would directly showcase many of the required skills.\n",
            "    * Build a REST API that interacts with a database and uses asynchronous tasks for background processing.\n",
            "    * Contribute to open-source projects related to web scraping or backend development.\n",
            "\n",
            "\n",
            "\n",
            "This revised resume focuses on the most relevant aspects of your experience and skills, highlighting your potential for success in the target role.  Remember to quantify your achievements wherever possible to demonstrate the impact of your work.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# setup api client\n",
        "genai.configure(api_key=\"Your API Key here\")\n",
        "\n",
        "# List available models and find one that supports generateContent\n",
        "available_models = list(genai.list_models())\n",
        "supported_model_name = None\n",
        "\n",
        "# Prioritize gemini-1.5-flash\n",
        "preferred_model = \"models/gemini-1.5-flash-latest\" # Using the latest version of 1.5-flash\n",
        "\n",
        "# Check if the preferred model is available and supported\n",
        "for m in available_models:\n",
        "    if m.name == preferred_model and \"generateContent\" in m.supported_generation_methods:\n",
        "        supported_model_name = m.name\n",
        "        print(f\"Using preferred model: {supported_model_name}\")\n",
        "        break # Found the preferred model, exit loop\n",
        "\n",
        "# If preferred model not found, find any other supported model\n",
        "if supported_model_name is None:\n",
        "    for m in available_models:\n",
        "        print(f\"Model Name: {m.name}\")\n",
        "        print(f\"Supported Generation Methods: {m.supported_generation_methods}\")\n",
        "        print(\"-\" * 20)\n",
        "        if \"generateContent\" in m.supported_generation_methods:\n",
        "            supported_model_name = m.name\n",
        "            print(f\"Using model: {supported_model_name}\")\n",
        "            break # Use the first supported model found\n",
        "\n",
        "if supported_model_name:\n",
        "    # Create a model instance using the correct model name from the list\n",
        "    model = genai.GenerativeModel(supported_model_name)\n",
        "\n",
        "    # Make the API call\n",
        "    response = model.generate_content(\n",
        "        [\n",
        "            # Remove the system role part as it's not supported by this model\n",
        "            # Incorporate system instructions into the user prompt if necessary\n",
        "            {\"role\": \"user\", \"parts\": [prompt]}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Extract the response\n",
        "    response_string = response.text\n",
        "\n",
        "    print(response_string)\n",
        "else:\n",
        "    print(\"No model supporting 'generateContent' found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DFv6WA1iywR"
      },
      "source": [
        "# **Display Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_Nwd9iYX7AW"
      },
      "outputs": [],
      "source": [
        "# separate new resume from improvement suggestions\n",
        "response_list = response_string.split(\"## Additional Suggestions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "BZIVGMbCi14P",
        "outputId": "e50483c0-669b-475b-97d5-ee99a143242e"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# P A Salman Shah\n",
              "\n",
              "üìû 7559967607  \n",
              "üìß salmansha8749@gmail.com  \n",
              "\n",
              "## Summary\n",
              "\n",
              "Highly motivated and results-oriented Python backend developer with experience in data analysis, web scraping, and API development seeking a challenging role leveraging asynchronous processing (Celery) and relational database management (PostgreSQL/MySQL). Proven ability to build scalable, maintainable, and well-tested applications using object-oriented programming principles.  Eager to contribute to a dynamic team and further develop expertise in cloud technologies (AWS) and containerization (Docker).\n",
              "\n",
              "## Skills\n",
              "\n",
              "* **Programming Languages:** Python (Django, FastAPI - *familiar*), SQL, JavaScript\n",
              "* **Frameworks/Libraries:** Celery,  Data Management Libraries (specify which ones from your projects),  Web Scraping Libraries (Beautiful Soup, Scrapy - *specify if used*),  REST API development\n",
              "* **Databases:** PostgreSQL, MySQL\n",
              "* **Tools:** Docker (familiar), Git,  Power BI, MS Excel\n",
              "* **Methodologies:** Object-Oriented Programming, Agile (mention if applicable)\n",
              "* **Other:**  Unit Testing, Logging,  Asynchronous Programming,  API Integration\n",
              "\n",
              "\n",
              "## Experience\n",
              "\n",
              "**Rever Tech IT Solutions - Web Mining using Python** (18/11/2022 ‚Äì 22/11/2022)\n",
              "\n",
              "* Developed Python scripts for web scraping, extracting specific data points and transforming them for analysis.  *(Quantify results if possible - e.g., \"Processed X amount of data points per hour\")*\n",
              "* Implemented data cleaning and preprocessing techniques to improve data quality for subsequent analysis.  *(Mention specific techniques used)*\n",
              "\n",
              "\n",
              "**Project: Phishing Website Detection Using Machine Learning**\n",
              "\n",
              "* Developed a machine learning model (LSD - LR + SVC + DT) for phishing website detection, employing both soft and hard voting mechanisms for improved accuracy. *(Quantify the accuracy improvement if possible)*\n",
              "\n",
              "\n",
              "**Project: YouTube Transcript Summarizer**\n",
              "\n",
              "* Designed and implemented a Chrome Extension utilizing a REST API and advanced NLP techniques to automatically summarize YouTube video transcripts. *(Mention NLP techniques used and any quantifiable results like summarization speed or accuracy)*\n",
              "\n",
              "\n",
              "## Education\n",
              "\n",
              "**Bachelor of Technology in Computer Science and Engineering**\n",
              "_College of Engineering Pathanapuram (2020‚Äì2024)_\n",
              "CGPA: 6.58\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(response_list[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoPMnWvqt5C1",
        "outputId": "14f4741c-8bc8-449a-b01a-0d2ca9453af8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:fontTools.ttLib.ttFont:Reading 'maxp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'maxp' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.011s to load 'maxp'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'maxp'\n",
            "INFO:fontTools.subset:maxp pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'cmap' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'cmap' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'post' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'post' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.013s to load 'cmap'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'cmap'\n",
            "INFO:fontTools.subset:cmap pruned\n",
            "INFO:fontTools.subset:fpgm dropped\n",
            "INFO:fontTools.subset:prep dropped\n",
            "INFO:fontTools.subset:cvt  dropped\n",
            "INFO:fontTools.subset:kern dropped\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to load 'post'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'post'\n",
            "INFO:fontTools.subset:post pruned\n",
            "INFO:fontTools.subset:GPOS dropped\n",
            "INFO:fontTools.subset:GSUB dropped\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'glyf' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'glyf' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'loca' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'loca' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'head' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'head' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.008s to load 'glyf'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to close glyph list over 'cmap'\n",
            "INFO:fontTools.subset:Added gid0 to subset\n",
            "INFO:fontTools.subset:Closing glyph list over 'glyf': 48 glyphs before\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'A', 'B', 'C', 'D', 'E', 'F', 'I', 'L', 'M', 'O', 'P', 'R', 'S', 'T', 'U', 'W', 'Y', 'a', 'b', 'bullet', 'c', 'colon', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 'slash', 't', 'u', 'uni00A0', 'uni00AD', 'v', 'w', 'x', 'y', 'z']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 16, 18, 29, 36, 37, 38, 39, 40, 41, 44, 47, 48, 50, 51, 53, 54, 55, 56, 58, 60, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 535]\n",
            "INFO:fontTools.subset:Closed glyph list over 'glyf': 48 glyphs after\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'A', 'B', 'C', 'D', 'E', 'F', 'I', 'L', 'M', 'O', 'P', 'R', 'S', 'T', 'U', 'W', 'Y', 'a', 'b', 'bullet', 'c', 'colon', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 'slash', 't', 'u', 'uni00A0', 'uni00AD', 'v', 'w', 'x', 'y', 'z']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 16, 18, 29, 36, 37, 38, 39, 40, 41, 44, 47, 48, 50, 51, 53, 54, 55, 56, 58, 60, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 535]\n",
            "DEBUG:fontTools.subset.timer:Took 0.010s to close glyph list over 'glyf'\n",
            "INFO:fontTools.subset:Retaining 48 glyphs\n",
            "INFO:fontTools.subset:head subsetting not needed\n",
            "INFO:fontTools.subset:hhea subsetting not needed\n",
            "INFO:fontTools.subset:maxp subsetting not needed\n",
            "INFO:fontTools.subset:OS/2 subsetting not needed\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hmtx' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hmtx' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hhea' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hhea' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.007s to subset 'hmtx'\n",
            "INFO:fontTools.subset:hmtx subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'cmap'\n",
            "INFO:fontTools.subset:cmap subsetted\n",
            "INFO:fontTools.subset:loca subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'post'\n",
            "INFO:fontTools.subset:post subsetted\n",
            "INFO:fontTools.subset:gasp subsetting not needed\n",
            "INFO:fontTools.subset:FFTM NOT subset; don't know how to subset\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'GDEF' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'GDEF' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.003s to subset 'GDEF'\n",
            "INFO:fontTools.subset:GDEF subsetted\n",
            "INFO:fontTools.subset:name subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to subset 'glyf'\n",
            "INFO:fontTools.subset:glyf subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset GlyphOrder\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'head'\n",
            "INFO:fontTools.subset:head pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'OS/2' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'OS/2' table\n",
            "INFO:fontTools.subset:OS/2 Unicode ranges pruned: [0, 1, 31]\n",
            "INFO:fontTools.subset:OS/2 CodePage ranges pruned: [0]\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'GDEF'\n",
            "INFO:fontTools.subset:GDEF pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'name' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'name' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'gasp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'gasp' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'FFTM' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'FFTM' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.013s to prune 'name'\n",
            "INFO:fontTools.subset:name pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'maxp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'maxp' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.003s to load 'maxp'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'maxp'\n",
            "INFO:fontTools.subset:maxp pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'cmap' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'cmap' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'post' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'post' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.007s to load 'cmap'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'cmap'\n",
            "INFO:fontTools.subset:cmap pruned\n",
            "INFO:fontTools.subset:fpgm dropped\n",
            "INFO:fontTools.subset:prep dropped\n",
            "INFO:fontTools.subset:cvt  dropped\n",
            "INFO:fontTools.subset:kern dropped\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to load 'post'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'post'\n",
            "INFO:fontTools.subset:post pruned\n",
            "INFO:fontTools.subset:GPOS dropped\n",
            "INFO:fontTools.subset:GSUB dropped\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'glyf' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'glyf' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'loca' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'loca' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'head' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'head' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.005s to load 'glyf'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to close glyph list over 'cmap'\n",
            "INFO:fontTools.subset:Added gid0 to subset\n",
            "INFO:fontTools.subset:Closing glyph list over 'glyf': 70 glyphs before\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'at', 'b', 'c', 'colon', 'comma', 'd', 'e', 'eight', 'endash', 'f', 'five', 'four', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'nine', 'o', 'one', 'p', 'parenleft', 'parenright', 'period', 'plus', 'q', 'r', 's', 'seven', 'six', 'slash', 't', 'two', 'u', 'uni00A0', 'uni00AD', 'v', 'w', 'x', 'y', 'z', 'zero']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 522]\n",
            "INFO:fontTools.subset:Closed glyph list over 'glyf': 70 glyphs after\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'at', 'b', 'c', 'colon', 'comma', 'd', 'e', 'eight', 'endash', 'f', 'five', 'four', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'nine', 'o', 'one', 'p', 'parenleft', 'parenright', 'period', 'plus', 'q', 'r', 's', 'seven', 'six', 'slash', 't', 'two', 'u', 'uni00A0', 'uni00AD', 'v', 'w', 'x', 'y', 'z', 'zero']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 522]\n",
            "DEBUG:fontTools.subset.timer:Took 0.005s to close glyph list over 'glyf'\n",
            "INFO:fontTools.subset:Retaining 70 glyphs\n",
            "INFO:fontTools.subset:head subsetting not needed\n",
            "INFO:fontTools.subset:hhea subsetting not needed\n",
            "INFO:fontTools.subset:maxp subsetting not needed\n",
            "INFO:fontTools.subset:OS/2 subsetting not needed\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hmtx' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hmtx' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hhea' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hhea' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.003s to subset 'hmtx'\n",
            "INFO:fontTools.subset:hmtx subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'cmap'\n",
            "INFO:fontTools.subset:cmap subsetted\n",
            "INFO:fontTools.subset:loca subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'post'\n",
            "INFO:fontTools.subset:post subsetted\n",
            "INFO:fontTools.subset:gasp subsetting not needed\n",
            "INFO:fontTools.subset:FFTM NOT subset; don't know how to subset\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'GDEF' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'GDEF' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.002s to subset 'GDEF'\n",
            "INFO:fontTools.subset:GDEF subsetted\n",
            "INFO:fontTools.subset:name subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to subset 'glyf'\n",
            "INFO:fontTools.subset:glyf subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset GlyphOrder\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'head'\n",
            "INFO:fontTools.subset:head pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'OS/2' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'OS/2' table\n",
            "INFO:fontTools.subset:OS/2 Unicode ranges pruned: [0, 1, 31]\n",
            "INFO:fontTools.subset:OS/2 CodePage ranges pruned: [0]\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'GDEF'\n",
            "INFO:fontTools.subset:GDEF pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'name' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'name' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'gasp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'gasp' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'FFTM' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'FFTM' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.005s to prune 'name'\n",
            "INFO:fontTools.subset:name pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'maxp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'maxp' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.002s to load 'maxp'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'maxp'\n",
            "INFO:fontTools.subset:maxp pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'cmap' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'cmap' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'post' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'post' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.006s to load 'cmap'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'cmap'\n",
            "INFO:fontTools.subset:cmap pruned\n",
            "INFO:fontTools.subset:fpgm dropped\n",
            "INFO:fontTools.subset:prep dropped\n",
            "INFO:fontTools.subset:cvt  dropped\n",
            "INFO:fontTools.subset:kern dropped\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to load 'post'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'post'\n",
            "INFO:fontTools.subset:post pruned\n",
            "INFO:fontTools.subset:GPOS dropped\n",
            "INFO:fontTools.subset:GSUB dropped\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'glyf' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'glyf' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'loca' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'loca' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'head' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'head' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.005s to load 'glyf'\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to close glyph list over 'cmap'\n",
            "INFO:fontTools.subset:Added gid0 to subset\n",
            "INFO:fontTools.subset:Closing glyph list over 'glyf': 43 glyphs before\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'C', 'E', 'L', 'M', 'N', 'P', 'Q', 'X', 'a', 'b', 'c', 'comma', 'd', 'e', 'endash', 'f', 'four', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'parenleft', 'parenright', 'period', 'q', 'quotedbl', 'r', 's', 't', 'two', 'u', 'uni00A0', 'uni00AD', 'v', 'y', 'z', 'zero']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 5, 11, 12, 15, 16, 17, 19, 21, 23, 38, 40, 47, 48, 49, 51, 52, 59, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 522]\n",
            "INFO:fontTools.subset:Closed glyph list over 'glyf': 43 glyphs after\n",
            "INFO:fontTools.subset:Glyph names: ['.notdef', 'C', 'E', 'L', 'M', 'N', 'P', 'Q', 'X', 'a', 'b', 'c', 'comma', 'd', 'e', 'endash', 'f', 'four', 'g', 'h', 'i', 'k', 'l', 'm', 'n', 'o', 'p', 'parenleft', 'parenright', 'period', 'q', 'quotedbl', 'r', 's', 't', 'two', 'u', 'uni00A0', 'uni00AD', 'v', 'y', 'z', 'zero']\n",
            "INFO:fontTools.subset:Glyph IDs:   [0, 3, 5, 11, 12, 15, 16, 17, 19, 21, 23, 38, 40, 47, 48, 49, 51, 52, 59, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 92, 93, 522]\n",
            "DEBUG:fontTools.subset.timer:Took 0.004s to close glyph list over 'glyf'\n",
            "INFO:fontTools.subset:Retaining 43 glyphs\n",
            "INFO:fontTools.subset:head subsetting not needed\n",
            "INFO:fontTools.subset:hhea subsetting not needed\n",
            "INFO:fontTools.subset:maxp subsetting not needed\n",
            "INFO:fontTools.subset:OS/2 subsetting not needed\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hmtx' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hmtx' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'hhea' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'hhea' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.003s to subset 'hmtx'\n",
            "INFO:fontTools.subset:hmtx subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'cmap'\n",
            "INFO:fontTools.subset:cmap subsetted\n",
            "INFO:fontTools.subset:loca subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset 'post'\n",
            "INFO:fontTools.subset:post subsetted\n",
            "INFO:fontTools.subset:gasp subsetting not needed\n",
            "INFO:fontTools.subset:FFTM NOT subset; don't know how to subset\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'GDEF' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'GDEF' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.002s to subset 'GDEF'\n",
            "INFO:fontTools.subset:GDEF subsetted\n",
            "INFO:fontTools.subset:name subsetting not needed\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to subset 'glyf'\n",
            "INFO:fontTools.subset:glyf subsetted\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to subset GlyphOrder\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'head'\n",
            "INFO:fontTools.subset:head pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'OS/2' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'OS/2' table\n",
            "INFO:fontTools.subset:OS/2 Unicode ranges pruned: [0, 1, 31]\n",
            "INFO:fontTools.subset:OS/2 CodePage ranges pruned: [0]\n",
            "DEBUG:fontTools.subset.timer:Took 0.001s to prune 'glyf'\n",
            "INFO:fontTools.subset:glyf pruned\n",
            "DEBUG:fontTools.subset.timer:Took 0.000s to prune 'GDEF'\n",
            "INFO:fontTools.subset:GDEF pruned\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'name' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'name' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'gasp' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'gasp' table\n",
            "DEBUG:fontTools.ttLib.ttFont:Reading 'FFTM' table from disk\n",
            "DEBUG:fontTools.ttLib.ttFont:Decompiling 'FFTM' table\n",
            "DEBUG:fontTools.subset.timer:Took 0.005s to prune 'name'\n",
            "INFO:fontTools.subset:name pruned\n"
          ]
        }
      ],
      "source": [
        "# save as PDF\n",
        "output_pdf_file = \"/content/salman_resume_new.pdf\"\n",
        "\n",
        "# Convert Markdown to HTML\n",
        "html_content = markdown(response_list[0])\n",
        "\n",
        "# Convert HTML to PDF and save\n",
        "HTML(string=html_content).write_pdf(output_pdf_file, stylesheets=['/content/style.css'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7p7CwIet5Ap"
      },
      "outputs": [],
      "source": [
        "# save as markdown\n",
        "output_file = \"resume_new.md\"\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "    file.write(response_list[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "CyvD4mAjt49z",
        "outputId": "0a6e58f6-d3d1-4531-8adf-e65f8b2bd8cc"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# P A Salman Shah\n",
              "\n",
              "üìû 7559967607  \n",
              "üìß salmansha8749@gmail.com  \n",
              "\n",
              "## Summary\n",
              "\n",
              "Highly motivated and results-oriented Python backend developer with experience in data analysis, web scraping, and API development seeking a challenging role leveraging asynchronous processing (Celery) and relational database management (PostgreSQL/MySQL). Proven ability to build scalable, maintainable, and well-tested applications using object-oriented programming principles.  Eager to contribute to a dynamic team and further develop expertise in cloud technologies (AWS) and containerization (Docker).\n",
              "\n",
              "## Skills\n",
              "\n",
              "* **Programming Languages:** Python (Django, FastAPI - *familiar*), SQL, JavaScript\n",
              "* **Frameworks/Libraries:** Celery,  Data Management Libraries (specify which ones from your projects),  Web Scraping Libraries (Beautiful Soup, Scrapy - *specify if used*),  REST API development\n",
              "* **Databases:** PostgreSQL, MySQL\n",
              "* **Tools:** Docker (familiar), Git,  Power BI, MS Excel\n",
              "* **Methodologies:** Object-Oriented Programming, Agile (mention if applicable)\n",
              "* **Other:**  Unit Testing, Logging,  Asynchronous Programming,  API Integration\n",
              "\n",
              "\n",
              "## Experience\n",
              "\n",
              "**Rever Tech IT Solutions - Web Mining using Python** (18/11/2022 ‚Äì 22/11/2022)\n",
              "\n",
              "* Developed Python scripts for web scraping, extracting specific data points and transforming them for analysis.  *(Quantify results if possible - e.g., \"Processed X amount of data points per hour\")*\n",
              "* Implemented data cleaning and preprocessing techniques to improve data quality for subsequent analysis.  *(Mention specific techniques used)*\n",
              "\n",
              "\n",
              "**Project: Phishing Website Detection Using Machine Learning**\n",
              "\n",
              "* Developed a machine learning model (LSD - LR + SVC + DT) for phishing website detection, employing both soft and hard voting mechanisms for improved accuracy. *(Quantify the accuracy improvement if possible)*\n",
              "\n",
              "\n",
              "**Project: YouTube Transcript Summarizer**\n",
              "\n",
              "* Designed and implemented a Chrome Extension utilizing a REST API and advanced NLP techniques to automatically summarize YouTube video transcripts. *(Mention NLP techniques used and any quantifiable results like summarization speed or accuracy)*\n",
              "\n",
              "\n",
              "## Education\n",
              "\n",
              "**Bachelor of Technology in Computer Science and Engineering**\n",
              "_College of Engineering Pathanapuram (2020‚Äì2024)_\n",
              "CGPA: 6.58\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Markdown(response_list[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QedlJO4wt43Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
